name: KB Newspaper Scraper

on:
  # For manual triggering
  workflow_dispatch:
    inputs:
      year:
        description: 'Year to scrape (e.g., 1865)'
        required: true
        default: '1865'
      month:
        description: 'Month to scrape (1-12)'
        required: true
        default: '1'
      operation:
        description: 'Operation to perform'
        required: true
        default: 'start-month'
        type: choice
        options:
          - start-month
          - continue-scraping
          - retry-failed
          - verify-month
      newspaper_ids:
        description: 'Newspaper IDs (comma-separated, leave empty for default)'
        required: false
        default: ''

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Configure Git
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
      # When starting a new month, process each day sequentially
      - name: Start month - Process days sequentially
        if: ${{ github.event.inputs.operation == 'start-month' }}
        run: |
          # Get days in month
          YEAR=${{ github.event.inputs.year }}
          MONTH=${{ github.event.inputs.month }}
          
          # Determine the number of days in the month
          DAYS_IN_MONTH=$(python -c "import calendar; print(calendar.monthrange(${YEAR}, ${MONTH})[1])")
          echo "Processing ${DAYS_IN_MONTH} days for ${YEAR}-${MONTH}"
          
          # Process each day one by one
          for day in $(seq 1 $DAYS_IN_MONTH); do
            # Format with leading zeros
            DAY_PADDED=$(printf "%02d" $day)
            DATE="${YEAR}-$(printf "%02d" $MONTH)-${DAY_PADDED}"
            NEXT_DATE=$(date -d "$DATE + 1 day" +"%Y-%m-%d")
            
            echo "----------------------------------------------------------------"
            echo "Processing day $day ($DATE) of $YEAR-$MONTH"
            echo "----------------------------------------------------------------"
            
            # Run the scraper for this day
            python src/01-scrape-images.py --start-date "$DATE" --end-date "$NEXT_DATE" --download-dir kb_newspapers --headless
            
            # Commit changes after each day to preserve progress
            git add kb_newspapers/ scraper_state.json
            git commit -m "Add scraped newspaper images for $DATE [skip ci]" || echo "No changes to commit for $DATE"
            git push origin main || echo "Failed to push for $DATE, will retry with the next day"
            
            # Optional: Add a small delay between days to avoid rate limiting
            sleep 5
          done
          
      # Handle other operations
      - name: Run scraper for other operations
        if: ${{ github.event.inputs.operation != 'start-month' }}
        run: |
          if [ "${{ github.event.inputs.operation }}" = "continue-scraping" ]; then
            python src/01-scrape-images.py --download-dir kb_newspapers --headless
          elif [ "${{ github.event.inputs.operation }}" = "retry-failed" ]; then
            python src/01-scrape-images.py --retry-failed --download-dir kb_newspapers --headless
          elif [ "${{ github.event.inputs.operation }}" = "verify-month" ]; then
            python src/01-scrape-images.py --verify-month --download-dir kb_newspapers --headless
          fi
          
      # Commit changes for other operations
      - name: Commit and push changes for other operations
        if: ${{ github.event.inputs.operation != 'start-month' }}
        run: |
          git add kb_newspapers/ scraper_state.json
          git commit -m "Update scraped data for ${{ github.event.inputs.operation }} [skip ci]" || echo "No changes to commit"
          git push origin main
          
      # Upload logs as artifacts
      - name: Upload scraper logs
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            kb_newspaper_cron.log
            kb_scraper.log
            
      - name: Upload scraper state
        uses: actions/upload-artifact@v4
        with:
          name: scraper-state
          path: scraper_state.json