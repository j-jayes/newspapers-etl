name: KB Newspaper Scraper

on:
  # For manual triggering
  workflow_dispatch:
    inputs:
      year:
        description: 'Year to scrape (e.g., 1865)'
        required: true
        default: '1865'
      month:
        description: 'Month to scrape (1-12)'
        required: true
        default: '1'
      operation:
        description: 'Operation to perform'
        required: true
        default: 'start-month'
        type: choice
        options:
          - start-month
          - continue-scraping
          - retry-failed
          - verify-month
      newspaper_ids:
        description: 'Newspaper IDs (comma-separated, leave empty for default)'
        required: false
        default: ''

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:

      - name: Free up disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          echo "After cleanup:"
          df -h


      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Configure Git
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
      # When starting a new month, process each day sequentially
      - name: Start month - Process days sequentially
        if: ${{ github.event.inputs.operation == 'start-month' }}
        run: |
          # Get days in month
          YEAR=${{ github.event.inputs.year }}
          MONTH=${{ github.event.inputs.month }}
          
          # Determine the number of days in the month
          DAYS_IN_MONTH=$(python -c "import calendar; print(calendar.monthrange(${YEAR}, ${MONTH})[1])")
          echo "Processing ${DAYS_IN_MONTH} days for ${YEAR}-${MONTH}"
          
          # Create an empty state file if it doesn't exist
          if [ ! -f "scraper_state.json" ]; then
            echo "{}" > scraper_state.json
            echo "Created empty scraper_state.json file"
          fi
          
          # Process each day one by one
          for day in $(seq 1 $DAYS_IN_MONTH); do
            # Format with leading zeros
            DAY_PADDED=$(printf "%02d" $day)
            DATE="${YEAR}-$(printf "%02d" $MONTH)-${DAY_PADDED}"
            NEXT_DATE=$(date -d "$DATE + 1 day" +"%Y-%m-%d")
            
            echo "----------------------------------------------------------------"
            echo "Processing day $day ($DATE) of $YEAR-$MONTH"
            echo "----------------------------------------------------------------"
            
            # Run the scraper for this day
            python src/01-scrape-images.py --start-date "$DATE" --end-date "$NEXT_DATE" --download-dir kb_newspapers --headless
            
            # Pull the latest changes to avoid conflicts
            git fetch origin main
            
            # Attempt to merge any remote changes; use ours (local) strategy for conflicts
            if git merge origin/main -X ours --no-edit; then
              echo "Successfully merged remote changes"
            else
              echo "Merge conflicts detected, resolving with our version"
              git reset --mixed origin/main
              git add -A
            fi
            
            # Check if the kb_newspapers directory exists before attempting to add it
            if [ -d "kb_newspapers" ]; then
              git add kb_newspapers/
            else
              echo "Warning: kb_newspapers directory not found, skipping git add"
            fi
            
            # Check if the state file exists
            if [ -f "scraper_state.json" ]; then
              git add scraper_state.json
            else
              echo "Warning: scraper_state.json not found, skipping git add"
              # Create an empty state file to avoid errors in future iterations
              echo "{}" > scraper_state.json
            fi
            
            # Attempt to commit and push with retries
            git commit -m "Add scraped newspaper images for $DATE [skip ci]" || echo "No changes to commit for $DATE"
            
            # Try to push with up to 3 retries
            MAX_RETRIES=3
            for attempt in $(seq 1 $MAX_RETRIES); do
              if git push origin main; then
                echo "Successfully pushed changes for $DATE"
                break
              else
                if [ $attempt -lt $MAX_RETRIES ]; then
                  echo "Push failed on attempt $attempt of $MAX_RETRIES, pulling and retrying..."
                  git pull origin main --rebase
                else
                  echo "Failed to push after $MAX_RETRIES attempts for $DATE, continuing with next day"
                fi
              fi
            done
            
            # Optional: Add a small delay between days to avoid rate limiting
            sleep 5
          done
          
      # Handle other operations
      - name: Run scraper for other operations
        if: ${{ github.event.inputs.operation != 'start-month' }}
        run: |
          if [ "${{ github.event.inputs.operation }}" = "continue-scraping" ]; then
            python src/01-scrape-images.py --download-dir kb_newspapers --headless
          elif [ "${{ github.event.inputs.operation }}" = "retry-failed" ]; then
            python src/01-scrape-images.py --retry-failed --download-dir kb_newspapers --headless
          elif [ "${{ github.event.inputs.operation }}" = "verify-month" ]; then
            python src/01-scrape-images.py --verify-month --download-dir kb_newspapers --headless
          fi
          
      # Commit changes for other operations
      - name: Commit and push changes for other operations
        if: ${{ github.event.inputs.operation != 'start-month' }}
        run: |
          # Create an empty state file if it doesn't exist
          if [ ! -f "scraper_state.json" ]; then
            echo "{}" > scraper_state.json
            echo "Created empty scraper_state.json file"
          fi
          
          # Pull the latest changes to avoid conflicts
          git fetch origin main
            
          # Attempt to merge any remote changes; use ours (local) strategy for conflicts
          if git merge origin/main -X ours --no-edit; then
            echo "Successfully merged remote changes"
          else
            echo "Merge conflicts detected, resolving with our version"
            git reset --mixed origin/main
            git add -A
          fi
          
          # Check if the kb_newspapers directory exists before attempting to add it
          if [ -d "kb_newspapers" ]; then
            git add kb_newspapers/
          else
            echo "Warning: kb_newspapers directory not found, skipping git add"
          fi
          
          # Check if the state file exists
          if [ -f "scraper_state.json" ]; then
            git add scraper_state.json
          else
            echo "Warning: scraper_state.json not found, skipping git add"
          fi
          
          # Attempt to commit and push with retries
          git commit -m "Update scraped data for ${{ github.event.inputs.operation }} [skip ci]" || echo "No changes to commit"
          
          # Try to push with up to 3 retries
          MAX_RETRIES=3
          for attempt in $(seq 1 $MAX_RETRIES); do
            if git push origin main; then
              echo "Successfully pushed changes"
              break
            else
              if [ $attempt -lt $MAX_RETRIES ]; then
                echo "Push failed on attempt $attempt of $MAX_RETRIES, pulling and retrying..."
                git pull origin main --rebase
              else
                echo "Failed to push after $MAX_RETRIES attempts"
              fi
            fi
          done
          
      # Upload logs as artifacts
      - name: Upload scraper logs
        uses: actions/upload-artifact@v4
        if: always()
        continue-on-error: true
        with:
          name: scraper-logs
          path: |
            *.log
            kb_newspaper_cron.log
            kb_scraper.log
            
      - name: Upload scraper state
        uses: actions/upload-artifact@v4
        if: always()
        continue-on-error: true
        with:
          name: scraper-state
          path: |
            scraper_state.json
            *state*.json